{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.bedrock import Bedrock\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = Bedrock(model=\"anthropic.claude-3-sonnet-20240229-v1:0\") \n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.graph_stores.neptune import NeptuneDatabaseGraphStore\n",
    "\n",
    "graph_store = NeptuneDatabaseGraphStore(\n",
    "    host=\"<NEPTUNE_DB>.<AWS_REGION>.neptune.amazonaws.com\", \n",
    "    port=8182,\n",
    "    node_label=\"User\"\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts.base import (\n",
    "    PromptTemplate,\n",
    "    PromptType,\n",
    ")\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "\n",
    "ENTITY_EXTRACT_TMPL_STR = \"\"\"\n",
    "A question is provided below. \n",
    "Given the question, extract up to {max_keywords} information that identify a given user in the question. Avoid stopwords.\n",
    "Focus on extracting complete information from question, it can be more than one single word.\n",
    "---------------------\n",
    "{question}\n",
    "---------------------\n",
    "Provide information in the following comma-separated format: 'KEYWORDS: <information>'\n",
    "\"\"\"\n",
    "\n",
    "ENTITY_EXTRACT_PROMPT = PromptTemplate(\n",
    "    ENTITY_EXTRACT_TMPL_STR,\n",
    "    prompt_type=PromptType.QUERY_KEYWORD_EXTRACT,\n",
    ")\n",
    "\n",
    "AMAZON_NEPTUNE_NL2CYPHER_PROMPT_TMPL_STR = \"\"\"\n",
    "Create a **Amazon Neptune flavor Cypher query** based on provided relationship paths and a question.\n",
    "The query should be able to try best answer the question with the given graph schema.\n",
    "The query should follow the following guidance:\n",
    "- Fully qualify property references with the node's label.\n",
    "```\n",
    "// Incorrect\n",
    "MATCH (p:person)-[:follow]->(:person) RETURN p.name\n",
    "// Correct\n",
    "MATCH (p:person)-[:follow]->(i:person) RETURN i.name\n",
    "```\n",
    "- Strictly follow the relationship on schema:\n",
    "Given the relationship ['(:`Art`)-[:`BY_ARTIST`]->(:`Artist`)']:\n",
    "```\n",
    "// Incorrect\n",
    "MATCH (a:Artist)-[:BY_ARTIST]->(t:Art)\n",
    "RETURN DISTINCT t\n",
    "// Correct\n",
    "MATCH (a:Art)-[:BY_ARTIST]->(t:Artist)\n",
    "RETURN DISTINCT t\n",
    "```\n",
    "- Follow single direction (from left to right) query model:\n",
    "```\n",
    "// Incorrect\n",
    "MATCH (a:Artist)<-[:BY_ARTIST]-(t:Art)\n",
    "RETURN DISTINCT t\n",
    "// Correct\n",
    "MATCH (a:Art)-[:BY_ARTIST]->(t:Artist)\n",
    "RETURN DISTINCT t\n",
    "```\n",
    "Given any relationship property, you should just use them following the relationship paths provided, respecting the direction of the relationship path.\n",
    "With these information, construct a Amazon Neptune Cypher query to provide the necessary information for answering the question, only return the plain text query, no explanation, apologies, or other text.\n",
    "NOTE:\n",
    "0. Try to get as much graph data as possible to answer the question\n",
    "1. Put a limit of 30 results in the query.\n",
    "---\n",
    "Question: {query_str}\n",
    "---\n",
    "Schema: {schema}\n",
    "---\n",
    "Amazon Neptune flavor Query:\n",
    "\"\"\"\n",
    "\n",
    "NL2CYPHER_PROMPT = PromptTemplate(\n",
    "    AMAZON_NEPTUNE_NL2CYPHER_PROMPT_TMPL_STR,\n",
    "    prompt_type=PromptType.TEXT_TO_GRAPH_QUERY,\n",
    ")\n",
    "\n",
    "graph_rag_retriever = KnowledgeGraphRAGRetriever(\n",
    "    storage_context=storage_context,\n",
    "    entity_extract_template=ENTITY_EXTRACT_PROMPT,\n",
    "    with_nl2graphquery=True,\n",
    "    graph_query_synthesis_prompt=NL2CYPHER_PROMPT,\n",
    "    graph_traversal_depth=3\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    graph_rag_retriever,\n",
    "    response_mode=\"refine\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "response = query_engine.query(\n",
    "\"\"\"\n",
    "You are a marketing analyst in a Technology retail company, mainly focused on selling notebooks, smartphones and tablets from popular brands.\n",
    "\n",
    "You need to create hyper-personalized product recommendation for this customer.\n",
    "\n",
    "Instructions for using the provided information about customer:\n",
    "\n",
    "1. You should recommend products similar to device models used by customer\n",
    "\n",
    "```\n",
    "// Example\n",
    "Given the device: Mozilla/5.0 (x11; Linux Amd64) Apple Web Kit/534.36 (khtml, Like Gecko) Chrome/13.0.766.0 Safari/534.36\n",
    "The device model is: x11; Linux Amd64\n",
    "```\n",
    "\n",
    "2. Web browser information is irrelevant\n",
    "3. Geographic information should be used to personalize your recommendation\n",
    "4. Ask for confirmation about contact information\n",
    "\n",
    "Notes:\n",
    "- Keep communication friendly and focused on recommending products models\n",
    "- Include technical details about recommended products models\n",
    "- Avoid mentioning your role\n",
    "- Avoid mentioning you are performing a personalized recommendation\n",
    "- Conclude by putting yourself available to support customer and answer questions\n",
    "\n",
    "Customer: <id>USER_ID</id>\n",
    "\"\"\",\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
