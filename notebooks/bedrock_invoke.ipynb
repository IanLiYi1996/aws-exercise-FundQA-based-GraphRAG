{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from botocore.config import Config\n",
    "\n",
    "\n",
    "config = Config(\n",
    "    region_name=\"us-east-1\",\n",
    "    signature_version='v4',\n",
    "    retries={\n",
    "        'max_attempts': 10,\n",
    "        'mode': 'standard'\n",
    "    },\n",
    "    read_timeout=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = None\n",
    "import json\n",
    "\n",
    "import logging\n",
    "\n",
    "def get_bedrock_client():\n",
    "    global bedrock\n",
    "    if not bedrock:\n",
    "        bedrock = boto3.client(service_name='bedrock-runtime', config=config)\n",
    "    return bedrock\n",
    "\n",
    "\n",
    "def invoke_llama_70b(model_id, system_prompt, user_prompt, max_tokens=2048, with_response_stream=False):\n",
    "    \"\"\"\n",
    "    Invoke LLama-70B model\n",
    "    :param model_id:\n",
    "    :param system_prompt:\n",
    "    :param messages:\n",
    "    :param max_tokens:\n",
    "    :param with_response_stream:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        llama3_prompt = \"\"\"\n",
    "        <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "        {system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "        {user_prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "        body = {\n",
    "            \"prompt\": llama3_prompt.format(system_prompt=system_prompt, user_prompt=user_prompt),\n",
    "            \"max_gen_len\": 2048,\n",
    "            \"temperature\": 0.01,\n",
    "            \"top_p\": 0.9\n",
    "        }\n",
    "        if with_response_stream:\n",
    "            response = get_bedrock_client().invoke_model_with_response_stream(body=json.dumps(body), modelId=model_id)\n",
    "            return response\n",
    "        else:\n",
    "            response = get_bedrock_client().invoke_model(\n",
    "                modelId=model_id, body=json.dumps(body)\n",
    "            )\n",
    "            response_body = json.loads(response[\"body\"].read())\n",
    "            return response_body\n",
    "    except Exception as e:\n",
    "        logging.error(\"Couldn't invoke LLama 70B\")\n",
    "        logging.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = invoke_llama_70b(\"meta.llama3-70b-instruct-v1:0\", \"You are a friendly conversation assistant\", \"who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generation': ' Hi there! I\\'m so happy to meet you! I\\'m a friendly conversation assistant, which means I\\'m a computer program designed to chat with you in a way that feels natural and fun. I don\\'t have a personal name, but you can call me \"Assistant\" or \"Chatbot\" if you like. My purpose is to help answer your questions, provide information, and even just have a nice conversation with you. I\\'m constantly learning and improving, so I can become a better conversationalist over time. What would you like to talk about?',\n",
       " 'prompt_token_count': 29,\n",
       " 'generation_token_count': 114,\n",
       " 'stop_reason': 'stop'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
